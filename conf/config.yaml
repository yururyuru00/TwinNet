key: GCN_Synthesis


# -------hydra & mlflow & optuna-------
# command: mlflow server --backend-store-uri sqlite:///tracking.db --default-artifact-root file:/tmp/artifacts --host 0.0.0.0

mlflow:
  server_ip: 192.168.11.30
  runname: test

defaults:
  - override hydra/sweeper: basic # [basic, optuna]

# hydra:
#   sweeper:
#     sampler:
#       _target_: optuna.samplers.TPESampler
#     direction: maximize
#     n_jobs: 1
#     n_trials: 100

# -------datasets (synthesis)-------

Synthesis: &Synthesis
  dataset: Synthesis
  data_type: small-scale
  n_feat: 2
  n_class: 10
  homophily: 0.8 # [0.0, 0.1, ..., 0.9]
  n_tri: 10
  epochs: 2000

# -------datasets (planetoid)-------

Planetoid: &Planetoid
  data_type: small-scale
  epochs: 200
  n_tri: 10
  debug_mode: False

Cora: &Cora
  <<: *Planetoid
  dataset: Cora
  x_normalize: False
  n_feat: 1433
  n_class: 7

CiteSeer: &CiteSeer
  <<: *Planetoid
  dataset: CiteSeer
  x_normalize: True
  n_feat: 3703
  n_class: 6

PubMed: &PubMed
  <<: *Planetoid
  dataset: PubMed
  x_normalize: False
  n_feat: 500
  n_class: 3


# -------datasets (web-kb)-------

WebKB: &WebKB
  data_type: small-scale
  epochs: 5000 # override >> GNN
  x_normalize: False
  n_feat: 1703
  n_tri: 10 # following original paper
  n_class: 5

Cornell: &Cornell
  <<: *WebKB
  dataset: Cornell

Texas: &Texas
  <<: *WebKB
  dataset: Texas

Wisconsin: &Wisconsin
  <<: *WebKB
  dataset: Wisconsin


# -------datasets (others)-------

PPI: &PPI
  dataset: PPI
  data_type: small-scale
  n_feat: 1 # num. of node feat
  e_feat: 8 # num. of edge feat
  n_class: 112
  n_tri: 3
  epochs: 1000 # override >> GNN

Arxiv: &Arxiv
  dataset: Arxiv
  data_type: small-scale
  n_feat: 128
  n_class: 40
  n_tri: 5
  epochs: 500 # override >> GNN

PPIinduct: &PPIinduct
  dataset: PPIinduct
  data_type: small-scale
  n_feat: 50
  n_class: 121
  n_tri: 5
  epochs: 200

Reddit: &Reddit
  dataset: Reddit
  data_type: large-scale
  n_feat: 602
  n_class: 41
  n_tri: 3
  epochs: 20 # override >> GNN

Products: &Products
  dataset: Products
  data_type: large-scale
  n_feat: 100
  n_class: 47
  n_tri: 1
  epochs: 20 # override >> GNN

MAG: &MAG
  dataset: MAG
  data_type: heterogeneous
  n_feat: 128
  n_class: 349
  n_tri: 3
  epochs: 100 # override >> GNN


# -------model interface-------

GNN: &GNN
  base_gnn: GNN
  global_skip_connection: vanilla # [vanilla, jk, twin]
  skip_connection: vanilla # [vanilla, res, dense, highway]
  n_layer: 3
  n_hid: 16
  dropout: 0.4
  learning_rate: 0.001
  weight_decay: 0.0001
  seed: 42
  patience: 100
  norm: None # [None, LayerNorm, BatchNorm1d]


# -------model instance-------

# Graph Convolution Networks (GCN)
GCN: &GCN
  <<: *GNN
  activation: ReLU
  base_gnn: GCN # override >> GNN

# Graph Attention Networks (GAT)
GAT: &GAT
  <<: *GNN
  activation: ELU
  base_gnn: GAT # override >> GNN
  n_head: 8
  n_head_last: 1

# Graph SAGE (SAGE)
SAGE: &SAGE
  <<: *GNN
  activation: ReLU
  base_gnn: SAGE # override >> GNN


# -------model instance + dataset-------

GCN_Synthesis: &GCN_Synthesis
  <<: [*Synthesis, *GCN]
  norm: LayerNorm
  n_layer: 2
  n_hid: 32
  dropout: 0.4
  learning_rate: 0.05
  weight_decay: 5e-4
  patience: 40

GAT_Synthesis: &GAT_Synthesis
  <<: [*Synthesis, *GAT]
  norm: LayerNorm
  n_layer: 2
  n_hid: 8
  dropout: 0.4
  learning_rate: 0.05
  weight_decay: 5e-4
  patience: 40

GCN_Cora: &GCN_Cora
  <<: [*Cora, *GCN]
  norm: None
  n_layer: 2
  n_hid: 16
  dropout: 0.4
  learning_rate: 0.01
  weight_decay: 0.001

GCN_CiteSeer: &GCN_CiteSeer
  <<: [*CiteSeer, *GCN]
  norm: LayerNorm
  n_layer: 2
  n_hid: 16
  dropout: 0.4
  learning_rate: 0.001
  weight_decay: 0.0005

GAT_PubMed: &GAT_PubMed
  <<: [*PubMed, *GAT]
  norm: LayerNorm
  n_layer: 2
  n_hid: 16
  dropout: 0.4
  learning_rate: 0.005
  weight_decay: 0.001

GCN_Cornell: &GCN_Cornell
  <<: [*Cornell, *GCN]
  norm: None
  n_layer: 2
  n_hid: 32
  dropout: 0.5
  learning_rate: 0.05
  weight_decay: 5e-6

GCN_Texas: &GCN_Texas
  <<: [*Texas, *GCN]
  norm: None
  n_layer: 2
  n_hid: 32
  dropout: 0.5
  learning_rate: 0.05
  weight_decay: 5e-6

GCN_Wisconsin: &GCN_Wisconsin
  <<: [*Wisconsin, *GCN]
  norm: None
  n_layer: 2
  n_hid: 32
  dropout: 0.5
  learning_rate: 0.05
  weight_decay: 5e-6

GAT_PPIinduct: &GAT_PPIinduct
  <<: [*PPIinduct, *GAT]
  skip_connection: highway
  norm: BatchNorm1d
  n_layer: 3
  n_hid: 256
  n_head: 4
  n_head_last: 6
  dropout: 0
  learning_rate: 0.001
  weight_decay: 0

GCN_Arxiv: &GCN_Arxiv
  <<: [*Arxiv, *GCN]
  norm: BatchNorm1d
  n_layer: 5
  n_hid: 256
  dropout: 0.5
  learning_rate: 0.001
  weight_decay: 0

SAGE_Reddit: &SAGE_Reddit
  <<: [*Reddit, *SAGE]
  norm: BatchNorm1d
  n_layer: 3
  n_hid: 256
  dropout: 0.3
  learning_rate: 0.001
  weight_decay: 0.0001

SAGE_PPI: &SAGE_PPI
  <<: [*PPI, *SAGE]
  norm: BatchNorm1d
  n_layer: 4
  n_hid: 256
  dropout: 0.6
  learning_rate: 0.005
  weight_decay: 0

SAGE_Products: &SAGE_Products
  <<: [*Products, *SAGE]
  norm: None
  n_layer: 3
  n_hid: 256
  dropout: 0.5
  learning_rate: 0.01
  weight_decay: 0

RGCN_MAG: &RGCN_MAG
  <<: [*MAG, *GCN]
  norm: None
  n_layer: 2
  n_hid: 64
  dropout: 0.5
  learning_rate: 0.01
  weight_decay: 0.0001 # 0.0001 or 0



# Jumping Knowledge Networks (JKNet)
JK: &JK
  global_skip_connection: jk # [vanilla, jk, twin]
  jk_mode: cat # [cat, max, lstm]


JKGCN_Cora: &JKGCN_Cora
  <<: [*JK, *GCN_Cora]

JKGCN_CiteSeer: &JKGCN_CiteSeer
  <<: [*JK, *GCN_CiteSeer]

JKGAT_PubMed: &JKGAT_PubMed
  <<: [*JK, *GAT_PubMed]

JKGAT_PPIinduct: &JKGAT_PPIinduct
  <<: [*JK, *GAT_PPIinduct]

JKGCN_Arxiv: &JKGCN_Arxiv
  <<: [*JK, *GCN_Arxiv]

JKSAGE_Reddit: &JKSAGE_Reddit
  <<: [*JK, *SAGE_Reddit]

JKSAGE_PPI: &JKSAGE_PPI
  <<: [*JK, *SAGE_PPI]

JKSAGE_Products: &JKSAGE_Products
  <<: [*JK, *SAGE_Products]

JKRGCN_MAG: &JKRGCN_MAG
  <<: [*JK, *RGCN_MAG]


# -------model instance (our study)-------

# Twin-Graph Neural Networks (Twin-GNN)
Twin: &Twin
  global_skip_connection: twin # [vanilla, jk, twin]
  scope: local # [local, global]
  kernel: wdp # [dp, sdp, wdp, ad, mx]
  temparature: 1 # \in R
  self_loop: True # [True, False]

# Synthesis
TwinGCN_Synthesis: &TwinGCN_Synthesis
  <<: [*Twin, *GCN_Synthesis]
  n_layer: 2

# Planetoid
TwinGCN_Cora: &TwinGCN_Cora
  <<: [*Twin, *GCN_Cora]
  n_layer: 9

TwinGCN_CiteSeer: &TwinGCN_CiteSeer
  <<: [*Twin, *GCN_CiteSeer]
  n_layer: 4
  temparature: 0.1

TwinGAT_PubMed: &TwinGAT_PubMed
  <<: [*Twin, *GAT_PubMed]
  n_layer: 7

# WebKB
TwinGCN_Cornell: &TwinGCN_Cornell
  <<: [*Twin, *GCN_Cornell]

TwinGCN_Texas: &TwinGCN_Texas
  <<: [*Twin, *GCN_Cornell]

TwinGCN_Wisconsin: &TwinGCN_Wisconsin
  <<: [*Twin, *GCN_Cornell]

# Others
TwinGAT_PPIinduct: &TwinGAT_PPIinduct
  <<: [*Twin, *GAT_PPIinduct]
  n_layer: 5
  scope: global
  temparature: -0.5

TwinGCN_Arxiv: &TwinGCN_Arxiv
  <<: [*Twin, *GCN_Arxiv]
  n_layer: 4

TwinSAGE_Reddit: &TwinSAGE_Reddit
  <<: [*Twin, *SAGE_Reddit]
  n_layer: 3
  scope: global
  temparature: -0.1

TwinSAGE_PPI: &TwinSAGE_PPI
  <<: [*Twin, *SAGE_PPI]
  n_layer: 7
  temparature: 0.5

TwinSAGE_Products: &TwinSAGE_Products
  <<: [*Twin, *SAGE_Products]
  # not yet tuning

TwinRGCN_MAG: &TwinRGCN_MAG
  <<: [*Twin, *RGCN_MAG]
  # not yet tuning
